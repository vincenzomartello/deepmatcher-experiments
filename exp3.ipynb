{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deepmatcher as dm\n",
    "from utilities_functions.intermediate_layer_extraction import return_layer_input_output\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchingModel(\n",
       "  (attr_summarizers): ModuleMap(\n",
       "    (Song_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Artist_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Album_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Genre): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Price): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (CopyRight): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Time): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Released): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_summarizer): Hybrid(\n",
       "  )\n",
       "  (attr_condensors): ModuleMap(\n",
       "    (Song_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Artist_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Album_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Genre): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Price): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (CopyRight): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Time): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Released): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_comparators): ModuleMap(\n",
       "    (Song_Name): Merge(\n",
       "    )\n",
       "    (Artist_Name): Merge(\n",
       "    )\n",
       "    (Album_Name): Merge(\n",
       "    )\n",
       "    (Genre): Merge(\n",
       "    )\n",
       "    (Price): Merge(\n",
       "    )\n",
       "    (CopyRight): Merge(\n",
       "    )\n",
       "    (Time): Merge(\n",
       "    )\n",
       "    (Released): Merge(\n",
       "    )\n",
       "  )\n",
       "  (attr_comparator): Merge(\n",
       "  )\n",
       "  (attr_merge): Merge(\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=1200, out_features=300, bias=True)\n",
       "        (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=1200, out_features=300, bias=True)\n",
       "        )\n",
       "        (1): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax_transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): None\n",
       "      )\n",
       "    )\n",
       "    (softmax): LogSoftmax()\n",
       "  )\n",
       "  (embed): ModuleMap(\n",
       "    (ltable_Song_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (ltable_Artist_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (ltable_Album_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (ltable_Genre): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (ltable_Price): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (ltable_CopyRight): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (ltable_Time): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (ltable_Released): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (rtable_Song_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (rtable_Artist_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (rtable_Album_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (rtable_Genre): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (rtable_Price): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (rtable_CopyRight): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (rtable_Time): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (rtable_Released): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model = dm.MatchingModel(attr_summarizer='hybrid')\n",
    "hybrid_model.load_state('models/hybrid2.pth')\n",
    "hybrid_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['Song_Name','Artist_Name','Album_Name','Genre','Price','CopyRight','Time','Released']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_classifier_inputs,neg_classifier_outputs,neg_ids = return_layer_input_output('sample_data/itunes-amazon/exp3'\n",
    "                                                                         ,'negatives.csv',32,hybrid_model,\n",
    "                                                                        hybrid_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_classifier_inputs,pos_classifier_outputs,pos_ids = return_layer_input_output('sample_data/itunes-amazon/exp3',\n",
    "                                                                       'positives.csv',32,hybrid_model,\n",
    "                                                                       hybrid_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pos_classifier_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_classifier_inputs = list(map(lambda x: x[0],neg_classifier_inputs))\n",
    "positive_classifier_inputs = list(map(lambda x: x[0],pos_classifier_inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities_functions.distance_measures import find_smallest_variation_to_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative sample analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_lenght= len(attributes)\n",
    "\n",
    "current_sample = 0\n",
    "#each column of this matrix is related to a specific attribute\n",
    "negatives_ri_matrix = []\n",
    "for batch in negative_classifier_inputs:\n",
    "    for index in range(len(batch)):\n",
    "        current_sample_ris = []\n",
    "        for j,attribute in enumerate(attributes):\n",
    "            print('Processing sample {} with attribute {}'.format(current_sample,attribute))\n",
    "            it,variation = find_smallest_variation_to_change(hybrid_model.classifier,batch,index,j,1)\n",
    "            current_sample_ris.append(variation)\n",
    "        negatives_ri_matrix.append(current_sample_ris)\n",
    "        current_sample+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_norms_negative_samples = []\n",
    "for ri_list in negatives_ri_matrix:\n",
    "    ri_norms_negative_samples.append(list(map(lambda x:torch.norm(x).data[0],ri_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "variation_df = pd.DataFrame(data= ri_norms_negative_samples,columns=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df['Price'].sum(),variation_df['Song_Name'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df['Album_Name'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df.to_csv('experiments-results/negative_samples_ri.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive samples analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_lenght= len(attributes)\n",
    "positive_samples_ri_matrix = []\n",
    "current_sample = 0\n",
    "\n",
    "for batch in positive_classifier_inputs:\n",
    "    for index in range(len(batch)):\n",
    "        current_sample_ris = []\n",
    "        for j,attribute in enumerate(attributes):\n",
    "            print('Processing sample {} with attribute {}'.format(current_sample,attribute))\n",
    "            it,variation = find_smallest_variation_to_change(hybrid_model.classifier,batch,index,j,0)\n",
    "            current_sample_ris.append(variation)\n",
    "        positive_samples_ri_matrix.append(current_sample_ris)\n",
    "        current_sample+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_norms = []\n",
    "for ri_list in positive_samples_ri_matrix:\n",
    "    ri_norms.append(list(map(lambda x:torch.norm(x).data[0],ri_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "variation_df = pd.DataFrame(data= ri_norms,columns=attributes)\n",
    "variation_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df.to_csv('experiments-results/positive_samples_ri_truegradient.csv',index=False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df['Price'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df['Artist_Name'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df['Time'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variation_df['Song_Name'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding closer vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "def get_closer_vector(v,batch_list):\n",
    "    min_distance = 10000000\n",
    "    i = 0\n",
    "    best_sample = i\n",
    "    for batch in batch_list:\n",
    "        for sample in batch:\n",
    "            curr_distance = euclidean(v.data,sample.data)\n",
    "            if curr_distance< min_distance:\n",
    "                min_distance = curr_distance\n",
    "                best_sample = i\n",
    "            i+=1\n",
    "    return best_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closer_vector_on_attribute(v,batch_list,attribute_idx,attribute_lenght):\n",
    "    min_distance = 1000000\n",
    "    i = 0\n",
    "    best_sample = i\n",
    "    start_index = attribute_idx*attribute_lenght\n",
    "    end_index = start_index+attribute_lenght\n",
    "    v_attribute_selected = v[start_index:end_index]\n",
    "    for batch in batch_list:\n",
    "        for sample in batch:\n",
    "            curr_distance = euclidean(v_attribute_selected.data,sample[start_index:end_index].data)\n",
    "            if curr_distance < min_distance:\n",
    "                min_distance = curr_distance\n",
    "                best_sample = i\n",
    "            i+=1\n",
    "    return best_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "closer_sample_index = get_closer_vector_on_attribute(positive_classifier_inputs[0][10],positive_classifier_inputs,0,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closer_sample_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = get_closer_vector_on_attribute(positive_classifier_inputs[4][5],negative_classifier_inputs,0,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_batches[4].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista di tuple: vettore pi vicino considerando tutti gli elementi e closer solo secondo un attributo\n",
    "closer_vectors = []\n",
    "i = 0\n",
    "for batch in negative_classifier_inputs:\n",
    "    for sample in batch:\n",
    "        # lista di coppie in cui il primo elemento indica il campione pi vicino considerando tutti gli elementi\n",
    "        # e il secondo indica il pi vicino considerando il singolo attributo\n",
    "        current_sample_closer_vectors = []\n",
    "        for j,attribute in enumerate(attributes):\n",
    "            curr_ri = negatives_ri_matrix[i][j]\n",
    "            altered_sample = sample + curr_ri\n",
    "            closer_index = get_closer_vector(altered_sample,positive_classifier_inputs)\n",
    "            closer_on_attribute = get_closer_vector_on_attribute(altered_sample,\n",
    "                                                                               positive_classifier_inputs,j,150)\n",
    "            current_sample_closer_vectors.append((closer_index,closer_on_attribute))\n",
    "        closer_vectors.append(current_sample_closer_vectors)\n",
    "        i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista di tuple: vettore piu' vicino, batch index e sample index\n",
    "positives_closer_vectors = []\n",
    "i = 0\n",
    "for batch in positive_classifier_inputs:\n",
    "    for sample in batch:\n",
    "        current_sample_closer_vectors = []\n",
    "        for j,attribute in enumerate(attributes):\n",
    "            curr_ri = positive_samples_ri_matrix[i][j]\n",
    "            altered_sample = sample + curr_ri\n",
    "            closer_index = get_closer_vector(altered_sample,negative_classifier_inputs)\n",
    "            closer_on_attribute_index = get_closer_vector_on_attribute(altered_sample,\n",
    "                                                                               negative_classifier_inputs,j,150)\n",
    "            current_sample_closer_vectors.append((closer_index,closer_on_attribute_index))\n",
    "        positives_closer_vectors.append(current_sample_closer_vectors)\n",
    "        i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_id_positives = []\n",
    "for batch in positive_batches:\n",
    "    ordered_id_positives = ordered_id_positives+batch.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_id_negatives = []\n",
    "for batch in negative_batches:\n",
    "    ordered_id_negatives = ordered_id_negatives+batch.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closer_vectors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_closer_vectors_df = pd.DataFrame(data= positives_closer_vectors,columns =attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_closer_vectors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_closer_vectors_df = pd.DataFrame(data = closer_vectors, columns = attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_closer_vectors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_closer_vectors_df = positives_closer_vectors_df.applymap(lambda c: (ordered_id_negatives[c[0]],\n",
    "                                                                   ordered_id_negatives[c[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_closer_vectors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_closer_vectors_df = negatives_closer_vectors_df.applymap(lambda c: (ordered_id_positives[c[0]],\n",
    "                                                                   ordered_id_positives[c[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_closer_vectors_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_closer_vectors_on_attribute_df = positives_closer_vectors_df.applymap(lambda c: c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_closer_vectors_on_attribute_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_closer_vectors_on_attribute_df = negatives_closer_vectors_df.applymap(lambda c : c[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_closer_vectors_df['Pos_sample_ID']= ordered_id_positives\n",
    "positives_closer_vectors_on_attribute_df['Pos_sample_ID'] = ordered_id_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_closer_vectors_df.to_csv('positives_closer_vectors.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_closer_vectors_on_attribute_df.to_csv('positives_closer_vectors_on_attribute.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_closer_vectors_df['Neg_sample_ID'] = ordered_id_negatives\n",
    "negatives_closer_vectors_on_attribute_df['Neg_sample_ID'] = ordered_id_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_closer_vectors_df.to_csv('negatives_closer_vectors.csv',sep=';',index=False)\n",
    "negatives_closer_vectors_on_attribute_df.to_csv('negatives_closer_vector_on_attribute.csv',sep=';',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it,variation = find_smallest_variation_to_change(hybrid_model.classifier,positive_classifier_inputs[0],20,6,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_classifier_inputs[0][20].data = positive_classifier_inputs[0][20].data.copy_(positive_classifier_inputs[0][20].data+\n",
    "                                                                                     variation.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.classifier.forward(positive_classifier_inputs[0])[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_list = []\n",
    "h = positive_classifier_inputs[0].register_hook(lambda g: grads_list.append(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = hybrid_model.classifier.forward(positive_classifier_inputs[0])\n",
    "prob = get_probabilites(out[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "true_labels = Variable (torch.cuda.FloatTensor([0,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
